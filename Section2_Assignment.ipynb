{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section2_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMv+2EI+0oET4hZjLZPFKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyscan6003/IntroToVision/blob/main/Section2_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbvJBKxZfYZF"
      },
      "source": [
        "#CE6021 Section 2 Assignment . - Scale Invariant \"blob\" keypoint detector. \n",
        "\n",
        "In this assignment you will code a scale invariant keypoint detector that can detect circular or blob like regions in an image. The goal of the assignment is to build a detector so that the dark circular regions in the centres of the sunflowers at different scales in the image can be found & marked.\n",
        "\n",
        "![](https://github.com/tonyscan6003/CE6003/blob/master/images/img_result.JPG?raw=true)\n",
        "\n",
        "As we have seen in the notes there are several possible ways to buid such a keypoint detector. For this assignment you will construct a Laplacian (of gaussian) scale space for the test image, and then seach this scale space for maxima that correspond to blobs in the image at different scales.\n",
        "\n",
        "We will firstly load the required python packages and import the test image of sunflowers and display it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ThvqEdde7xV"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "from scipy import signal\n",
        "from tqdm import tqdm  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPgjOFmgf4LD"
      },
      "source": [
        "image_url_flowers = \"https://t.wallpaperweb.org/wallpaper/nature/1600x1200/Field_of_Sunflowers_Kentucky.jpg\"\n",
        "\n",
        "# Function to read images from the Web.\n",
        "def url_to_image(url):\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\ttemp_image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\ttemp_image = cv2.imdecode(temp_image, cv2.IMREAD_COLOR)\n",
        "\ttemp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB) # OpenCV defaults to BGR, but we need RGB here..\n",
        "\treturn temp_image\n",
        "\n",
        "def read_image():\n",
        "   # read Image \n",
        "   sf =2\n",
        "   image = url_to_image(image_url_flowers)\n",
        "   #Scale Image by sf = 2\n",
        "   x,y,z = np.shape(image)\n",
        "   image_scale = cv2.resize(image, dsize=(int(y/sf), int(x/sf)), interpolation=cv2.INTER_CUBIC)\n",
        "   #Convert to Greyscale\n",
        "   gray = cv2.cvtColor(image_scale, cv2.COLOR_BGR2GRAY)\n",
        "   return image_scale,gray\n",
        "\n",
        "image_scale,gray = read_image()\n",
        "plt.imshow(image_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsamDD57xxYm"
      },
      "source": [
        "# Laplacian Scale Space:\n",
        "\n",
        "Our goal in this section is to generate a laplacian scale space for the test image. We will perform this in three steps.\n",
        "\n",
        "> **Step 1**: We will code a function that can generate kernel functions i.e. the 2nd order paratial derivatives of the gaussian function  $\\frac{\\partial^2{G(\\mathbf{x},\\sigma)}}{\\partial{x}^2}$,$\\frac{\\partial^2{G(\\mathbf{x},\\sigma)}}{\\partial{y}^2}$. \n",
        "\n",
        "> **step 2**: We will code a function that convolves the image with gaussian derivative kernels to produce the Laplacian of Gaussians for any value of sigma.\n",
        "\n",
        "> **Step 3**: We will use the convolution function we have just written in a for loop to create the scale space images and assign them to an array.\n",
        "\n",
        "**Computation of kernels:**\n",
        "As shown in the notes 2_2 (part B) (slide 4) the Laplacian scale space (for a given sigma) is formed from convolution of the partial derivatives of the gaussian kernel with the input image.\n",
        "It is however computationally inefficient to convolve these large 2d kernels with the image. *Therefore the gaussian partial derivative kernels should be instead determined as seperable convoutions*. That is 2 sequential convolutions with 1d kernels. \n",
        "\n",
        "Useful Information:\n",
        "> The gaussian 1d forms including the 1st and 2nd order derivatives can be found [here](http://www.sci.utah.edu/~gerig/CS7960-S2010/handouts/04%20Gaussian%20derivatives.pdf)\n",
        "\n",
        "> Seperable convolutions: Lecture 1_2 & [here](http://www.songho.ca/dsp/convolution/convolution2d_separable.html)\n",
        "\n",
        "> [Scipy 2d Convolution command](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html) (can be used with 1xn arrays as well as m x n):\n",
        "\n",
        "> Numpy expand dims can be used to turn a list into an array\n",
        "\n",
        "> Numpy transpose can be used to obtain transpose of an array\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NeaPz977rK3"
      },
      "source": [
        "**Scale space range**: The code cell below defines a range of sigma values to generate your scale space over."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mUBYQ_N7nhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1d57515-ab7e-4e69-c2bb-29a012dc3548"
      },
      "source": [
        "# Define Scale space\n",
        "sigma_min = 1\n",
        "sigma_max = 32\n",
        "scale_fac = 1.05\n",
        "# number of filters in scale space\n",
        "num_scales = int((sigma_max-sigma_min)/scale_fac)\n",
        "print(\"The number of scales is \",num_scales)\n",
        "sigma_vals = np.linspace(sigma_min,sigma_max,num_scales) # Range of sigma values for scale space"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of scales is  29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDddubD28POW"
      },
      "source": [
        "**Step 1:** In the code cell below you should complete the function that can output the 1d kernels that can be used to form the 2d Gaussians derivative kernels $\\frac{\\partial^2{G(\\mathbf{x},\\sigma)}}{\\partial{x}^2}$,$\\frac{\\partial^2{G(\\mathbf{x},\\sigma)}}{\\partial{y}^2}$ for a given sigma value. Hint: The same two 1d kernels are necessary to generate both 2D gaussian derivative kernels.\n",
        "\n",
        "Note \n",
        "> When generating 1d gaussian kernels it is necessary to ensure there are enough samples in the window for the gaussian to decay to zero (see lecture 1_2). With larger sigma values bigger kernels are needed. The code snippet below gives the range of samples needed for generating gaussian kernels of different sizes.\n",
        "```\n",
        "    k_size = int(6*sigma+1)\n",
        "    rng = (k_size-1)//2\n",
        "    x = np.arange(-rng,rng+1)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQy-RC7vUQRz"
      },
      "source": [
        "# Determines kernels for partial derivatives \n",
        "def gauss_kernels(sigma):\n",
        "    \"\"\"\n",
        "    sigma: Parameter controlling Gaussian blur\n",
        "    K1: 1d kernel 1 x 2*rng+1 array \n",
        "    K2: 1d kernel 1 x 2*rng+1 array \n",
        "    \"\"\"\n",
        "    # Work out necessary kernel size and range to generate gaussian over.\n",
        "    k_size = int(6*sigma+1)\n",
        "    rng = (k_size-1)//2\n",
        "    x = np.arange(-rng,rng+1) \n",
        "\n",
        "    # Define 1 dimensional gaussian kernels \n",
        "\n",
        "    #### Your Code Here ###  \n",
        "\n",
        "    return K1,K2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcCsOfMmJ55y"
      },
      "source": [
        "Before moving to the next step, You can test if you can correctly generate the required 2D kernels from the 1D kernels by obtaining the outer product of the 1d kernels and plotting the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSyu9SuSUnyL"
      },
      "source": [
        "K1,K2 = gauss_kernels(15)\n",
        "K_2d_x = # Add a simple expression to determine the 2D 2nd order gaussian derivative in the x direction\n",
        "K_2d_y = # Add a simple expression to determine the 2D 2nd order gaussian derivative in the y direction\n",
        "\n",
        "num_filt=2\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "from mpl_toolkits import mplot3d\n",
        "def plot_filter(A,i):\n",
        "   ax = fig.add_subplot(num_filt,2, i)\n",
        "   ax.imshow(A,'gray') \n",
        "plot_filter(K_2d_x,1) \n",
        "plot_filter(K_2d_y,2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPUkxu0-Q049"
      },
      "source": [
        "**Step 2:** In the code cell below you should complete the function that can output the normalised lapacian of a greyscale image for a given sigma value. You can re-use the function to generate the 1d kernels and then convolve the input image using seperable convolution as mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unZHFzrYhWyg"
      },
      "source": [
        "#### Your Code Here ### \n",
        "def laplacian(sigma,image):\n",
        "    \"\"\"\n",
        "    sigma: Parameter controlling Gaussian blur\n",
        "    image: input greyscale image n x m\n",
        "    conv_laplacian: output image n x m to be returned, \n",
        "                    result of convolution of image with laplacian of Gaussian  \n",
        "    \"\"\"\n",
        "    # 1 dimension gaussian kernels (Integration scale)\n",
        "    K1,K2 = gauss_kernels(sigma)\n",
        "\n",
        "    # Form Derivatives of Image with Gaussian (with sequential 1d convolution.)\n",
        "\n",
        "    #### Your Code Here ### \n",
        "\n",
        "    return conv_laplacian\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmKRrKkMyfdo"
      },
      "source": [
        "**Step 3:** Using the function that you have written, we will now iterate through the given sigma values and stack (using dstack) each scale space image to the array `laplace_scale_space`. This output array should be of dimension $n\\times m \\times k$ where $n$ and $m$ are the dimensions of the image and $k$ is the number of scales (`num_scales`).\n",
        "We use greyscale image `gray` with your function along with each sigma value (not the original color image).\n",
        "\n",
        "np.dstack: https://docs.scipy.org/doc/numpy/reference/generated/numpy.dstack.html\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "craULlpysB0H"
      },
      "source": [
        "\n",
        "# Initialise sscale space as empty\n",
        "laplace_scale_space = []\n",
        "# Initialise pointer\n",
        "ptr = 0\n",
        "\n",
        "for k in tqdm(range(num_scales)): # For each sigma in scale space\n",
        "   #Generate matrix components\n",
        "   conv_laplacian = laplacian(sigma_vals[k],gray)\n",
        "   # add to scale space\n",
        "   laplace_scale_space = np.dstack((laplace_scale_space,conv_laplacian)) if ptr>0 else conv_laplacian\n",
        "   #update pointer\n",
        "   ptr += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDdaEYhHEV7u"
      },
      "source": [
        "print(np.shape(laplace_scale_space))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey73GRtYw7J-"
      },
      "source": [
        "**View Lapacian Scale Space** If you have correctly generated the lapacian scale space, you can use the function in the cell below to visualise the scale space. The function will plot the laplacian and the square of the laplacian. (Note that your laplacian scale space will contain both positive and negative values, but the plot function will automatically offset and scale the values for dispay)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOF60x070HDF"
      },
      "source": [
        "fig = plt.figure(figsize=(20,200))\n",
        "\n",
        "def plot_filter(A,B,sigma,i):\n",
        "   title_val = np.round(sigma,decimals=1)\n",
        "   ax = fig.add_subplot(num_scales, 2, 2*(i+1)-1)\n",
        "   ax.imshow(A,'gray')\n",
        "   ax.title.set_text('LoG Image, Sigma Value = '+str(title_val))\n",
        "   ax.axis('off')\n",
        "   ax = fig.add_subplot(num_scales, 2, 2*(i+1))\n",
        "   ax.imshow(B,'jet')\n",
        "   ax.title.set_text('Sq Norm Lapacian')\n",
        "\n",
        "ptr =0\n",
        "# View Laplacian Scale space\n",
        "for i in range(0,24,2):\n",
        "    sigma = sigma_vals[i]\n",
        "    laplace_conv = laplace_scale_space[:,:,i] \n",
        "    # Obtain square norm\n",
        "    sq_norm = laplace_conv**2\n",
        "    # Call plotting\n",
        "    plot_filter(laplace_conv,sq_norm,sigma,ptr)\n",
        "    ptr+=1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "749WQ4hYxADl"
      },
      "source": [
        "# Maxima Detection.\n",
        "If you have completed the notebook successfuly to this point, you should be able to see the maxima in the Normalised Laplacian image that you generated correspond to the stuctures in the original image. It should be evident that the reponse is maximised at particular scales (sigma values) and at particular locations in the image. (Images should be similar to slide 3 of lecture 2_2 part B)\n",
        "\n",
        "The next step is to find the exact location of the local maxima in x,y space and scale. This may be achieved by iterating though all of the scale space images and determining if each point in scale space is a local maximum by comparing it's magnitude with each of it's 26 nearest neighbours (as shown in slide 6 of the lecture slides 2_2 part B). You should be able to convince yourself with a simple 1d example that this algorithm can find local maxima over all scales and positions.\n",
        "\n",
        "In the code cell below complete the function `lap_max_det` . This function sets the conditions for detection of a maxima.  A threshold value `thresh` should be included to ensure that we include the strong maxima and avoid too many detections. This function should return a list `max_det` when a maxima is detected (it returns an empty list otherwise). The magnitude of the detected maximum in Laplacian scale space, the x,y position and the scale sigma are stored in the list.  \n",
        "\n",
        "The lap_max_det function is then used in the function `find_maxima` which contains a for loop (given) that iterates over all points in scale space and applies your condition to detect maxima.\n",
        "\n",
        "Notes:\n",
        "\n",
        "> The first and last images in the scale space are treated as auxillary images (i.e. These scale spaced are only used to assist in the determination of maxima of the 2nd and 2nd last layers.) \n",
        "\n",
        "> The numpy [ravel](https://numpy.org/doc/stable/reference/generated/numpy.ravel.html) command may be useful\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-NOZzLlwct9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cb7bbe5-6eb0-43db-f2fc-22faae7a0da9"
      },
      "source": [
        "ws = 3  # Window size used for nearest neighbours \n",
        "max_coords = np.empty((1,4)) # Array to store detected coordinates\n",
        "eps = 1e-3 # Small epsilon value\n",
        "n_max = 0 # Initialise variable counting no. maxima detected\n",
        "thresh = 40 # Choose Threshold value\n",
        "\n",
        "\n",
        "\n",
        "# Comparision with Nearest Neighbours for maxima detection\n",
        "def lap_max_det(x,y,k,thresh):\n",
        "    sigma = sigma_vals[k]    # Associated sigma current scale\n",
        "    \"\"\"\n",
        "      x,y,k: are current point coordinates in scale space.\n",
        "      thresh: is a threshold to ignore values. \n",
        "      det_max: is a list containing, [mag, x, y, sigma ] \n",
        "                  mag: magnitude of maxium in scale space\n",
        "                  x,y spatial coordinates\n",
        "                  value of sigma for current scale\n",
        "      laplace_scale_space: previously created array in notebook containing scale spaces \n",
        "    \"\"\"\n",
        "    # From Laplace Scale Space: Obtain magnitude of test point and \n",
        "    # nearest neighbours for comparison.\n",
        "\n",
        "    #### Your Code Here ###  \n",
        "\n",
        "    # Condition for max detection\n",
        "    if #### Your Code Here ###       \n",
        "        det_max = [test_point,x,y,sigma]\n",
        "    else:\n",
        "        det_max =[]    # Output empty list if no max detected\n",
        "    return det_max\n",
        "\n",
        "\n",
        "x_max,y_max = np.shape(gray) \n",
        "def find_maxima(max_coords,n_max):\n",
        "   \"\"\"\n",
        "      max_coords: is an array size n_max x 4 where n_max are the number of maxima found\n",
        "                  each row contains, [mag, x, y, sigma ] \n",
        "                  mag: magnitude of detected maximum in scale space\n",
        "                  x,y spatial coordinates\n",
        "                  value of sigma for current scale.\n",
        "   \"\"\"            \n",
        "   # Iterate over scales\n",
        "   for k in tqdm(range(1,num_scales-1)):\n",
        "      # Iterate over spatial points\n",
        "      for x in range(1,x_max-ws):\n",
        "         for y in range(1,y_max-ws):\n",
        "\n",
        "           det_max=lap_max_det(x,y,k,thresh)\n",
        "\n",
        "           if det_max: # Add valid maxima to array\n",
        "             max_coords = np.concatenate((max_coords,np.array([det_max]))) if n_max>0 else np.array([det_max])\n",
        "             n_max+=1 \n",
        "\n",
        "   return max_coords,n_max \n",
        "\n",
        "\n",
        "max_coords,n_max = find_maxima(max_coords,n_max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [01:50<00:00,  4.09s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ep5Icb7yX5k"
      },
      "source": [
        "**Display Maxima** The code below is provided to help you display you found keypoints over the original image. (some minor modification may be necessary depending on how you stored the keypoints from the last cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmTmw4w5hVKd"
      },
      "source": [
        "# Sort the maxima and draw largest 250 on the iamge \n",
        "image,gray = read_image()\n",
        "\n",
        "\n",
        "# sort in descending order (using magnitude)\n",
        "index_coords=np.argsort(max_coords[:,0],axis=0)[::-1]\n",
        "\n",
        "for i in index_coords[0:n_max]:\n",
        "    [mag,x,y,sigma] = max_coords[i,:]\n",
        "    br =int(math.ceil(1.414 * sigma))\n",
        "    keypoints_img = cv2.circle(image, (int(y),int(x)), br, (255,0,0), 1)\n",
        "\n",
        "\n",
        "# Plot keypoint image\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(keypoints_img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaSWRGitQNB5"
      },
      "source": [
        "**Comments:** Please leave any comments in this text box that you have on your results or approach for your moderator."
      ]
    }
  ]
}